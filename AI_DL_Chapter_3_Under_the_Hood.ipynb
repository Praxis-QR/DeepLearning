{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI DL Chapter 3 - Under the Hood",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/DeepLearning/blob/main/AI_DL_Chapter_3_Under_the_Hood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NOhrvHmSArF"
      },
      "source": [
        "![alt text](https://1.bp.blogspot.com/-WAjYIaQofo0/YEB0cQsSGSI/AAAAAAAAkoE/TpQcWBRGtu0N010lmiTS9cFHuGwXB45PQCLcBGAsYHQ/s16000/colabHeader00.png)<br>\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.yantrajaal.com) / [Praxis Business School](http://praxis.ac.in/) / [Book Website](http://aidl4managers.blogspot.com) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLBz055asDAy"
      },
      "source": [
        "Base Solultion https://stackoverflow.com/questions/37520849/cant-approximate-simple-multiplication-function-in-neural-network-with-1-hidden <br>\n",
        "Overview of NN https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lp8slFeQdT2"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cGlb-afszzy"
      },
      "source": [
        "test=[[.2,.5],[.3,.6],[.4,.7],[.5,.8],[.6,.9]]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvA96Kd1orMp",
        "outputId": "04d60fae-3fa5-4b69-e8e3-3449cfd940c3"
      },
      "source": [
        "train = np.random.random((10000, 2))\n",
        "results = np.asarray([a * b for a, b in train])\n",
        "train[0:5,:], results[0:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.41486323, 0.7470981 ],\n",
              "        [0.82140391, 0.63749929],\n",
              "        [0.63782051, 0.90215892],\n",
              "        [0.54898375, 0.14132535],\n",
              "        [0.65262974, 0.28962669]]),\n",
              " array([0.30994353, 0.52364441, 0.57541547, 0.07758532, 0.18901899]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-iwKnUpvZCt"
      },
      "source": [
        "#Simple Model model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyuZ3Wdvy5E6"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import callbacks"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy_PnBQgQpev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b480ab-23ac-450e-f858-51520e265397"
      },
      "source": [
        "model1B = models.Sequential()\n",
        "model1B.add(layers.Dense(150, activation='relu', input_shape=(2,)))\n",
        "model1B.add(layers.Dense(1, activation='relu'))\n",
        "model1B.compile(optimizer='sgd', loss='mae')\n",
        "model1B.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 150)               450       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 151       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 601\n",
            "Trainable params: 601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "038XCgyDQ0dc",
        "outputId": "1898f143-3dde-4bb9-f9ae-035357bf9bb8"
      },
      "source": [
        "model1B.fit(train, results, epochs=5, batch_size=1)\n",
        "#model1.fit(train, results, epochs=5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 0.0288\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 0.0136\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0118\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 0.0112\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 12s 1ms/step - loss: 0.0109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe44946f590>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-0tiMuKnd0w",
        "outputId": "237a1498-34e1-465c-8c7f-b6cfa8724d4f"
      },
      "source": [
        "test_result = model1B.predict(test)\n",
        "test,test_result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.11603371],\n",
              "        [0.19596484],\n",
              "        [0.2988634 ],\n",
              "        [0.41728818],\n",
              "        [0.5564184 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77I4_yHUvedI"
      },
      "source": [
        "#Better Model : model2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4hS7SGyqgTH",
        "outputId": "92abeab0-1431-4a67-87b8-5c195b8ba415"
      },
      "source": [
        "model2A = models.Sequential()\n",
        "model2A.add(layers.Dense(4096*4, activation='relu', input_shape=(2,)))\n",
        "model2A.add(layers.Dense(1, activation='linear'))\n",
        "model2A.compile(optimizer='adam', loss='mse')\n",
        "model2A.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 16384)             49152     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 16385     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp8lyiPLrFd_",
        "outputId": "4f4ed142-b2e4-42b6-d857-e9ce3befdf73"
      },
      "source": [
        "model2A.fit(train, results, epochs=100, batch_size=512)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0264\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0029\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0015\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0011\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 7.7361e-04\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 5.2653e-04\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.3572e-04\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 2.0407e-04\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.2945e-04\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 9.1137e-05\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 6.8813e-05\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 5.3195e-05\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 4.2874e-05\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.3764e-05\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.7322e-05\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 2.2488e-05\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.8974e-05\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.5748e-05\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.3330e-05\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.1305e-05\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 9.7040e-06\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 8.7671e-06\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 7.6246e-06\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 6.8358e-06\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 5.9706e-06\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 5.4476e-06\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 4.8043e-06\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 4.4285e-06\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 4.2978e-06\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.7930e-06\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 3.3689e-06\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.1565e-06\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 2.9107e-06\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 2.8905e-06\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.5726e-06\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.2962e-06\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.0985e-06\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.9966e-06\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 1.8535e-06\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.7770e-06\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.6530e-06\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.5024e-06\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.4636e-06\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 1.4426e-06\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.2724e-06\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.2385e-06\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.1489e-06\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.1834e-06\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 1.0145e-06\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 9.8057e-07\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 9.4277e-07\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 9.0778e-07\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 8.9719e-07\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 8.6871e-07\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 7.6509e-07\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 7.3618e-07\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 7.4576e-07\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 7.6797e-07\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 6.4257e-07\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 6.1464e-07\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 5.9679e-07\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 5.7832e-07\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 5.5278e-07\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 5.3079e-07\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 5.3648e-07\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 5.6554e-07\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 4.8804e-07\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 5.0156e-07\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 4.5981e-07\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 4.3072e-07\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.9906e-07\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.7720e-07\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.7598e-07\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.7682e-07\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.3568e-07\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.2911e-07\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 4.0051e-07\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.3099e-07\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.3491e-07\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.4886e-07\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.1942e-07\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.9171e-07\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 3.2174e-07\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 3.0854e-07\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.8471e-07\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 2.4078e-07\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 2.5524e-07\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 1s 71ms/step - loss: 2.5496e-07\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 1s 73ms/step - loss: 2.2294e-07\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.1466e-07\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.7318e-07\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.5266e-07\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.1537e-07\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.1167e-07\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.6595e-07\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 2.3613e-07\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.3336e-07\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.8749e-07\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 2.1369e-07\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.7095e-07\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe44bf61d90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYdQtrXrthE",
        "outputId": "d6a35449-0ebd-4c55-db01-9bdc79e7e4f5"
      },
      "source": [
        "test_results_2A = model2A.predict(test)\n",
        "test,test_results_2A"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.1002232 ],\n",
              "        [0.18029156],\n",
              "        [0.28022423],\n",
              "        [0.40044835],\n",
              "        [0.5404367 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNy-n7IbzRvy",
        "outputId": "54b129f3-9d04-49a1-bb76-1615167f4c8e"
      },
      "source": [
        "test_result = model1B.predict(test)\n",
        "test,test_result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.11603371],\n",
              "        [0.19596484],\n",
              "        [0.2988634 ],\n",
              "        [0.41728818],\n",
              "        [0.5564184 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W53HoOusHlG",
        "outputId": "c9566d79-1c86-4b42-bbb3-80816999f07f"
      },
      "source": [
        "from keras import callbacks\n",
        "callbacks = [callbacks.EarlyStopping(patience=6), callbacks.ReduceLROnPlateau()]\n",
        "model2A.fit(train, results, epochs=100, batch_size=512, validation_split=0.3, callbacks=callbacks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 2.0250e-07 - val_loss: 3.9083e-07 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 2.3732e-07 - val_loss: 1.9747e-07 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.7460e-07 - val_loss: 1.6095e-07 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.5382e-07 - val_loss: 1.3321e-07 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.6397e-07 - val_loss: 1.2850e-07 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 1.5955e-07 - val_loss: 1.3408e-07 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.8450e-07 - val_loss: 3.3214e-07 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 1.8721e-07 - val_loss: 2.4359e-07 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 3.6168e-07 - val_loss: 1.5967e-07 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 2.8549e-07 - val_loss: 4.6859e-07 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 2.9575e-07 - val_loss: 2.2130e-07 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe44b669fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG1-TU1rv0g4",
        "outputId": "511494d5-0e13-49f2-fc9a-62d030f7af6c"
      },
      "source": [
        "test_results_2 = model2A.predict(test)\n",
        "test,test_results_2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.09987218],\n",
              "        [0.17976484],\n",
              "        [0.27954772],\n",
              "        [0.39958486],\n",
              "        [0.5393298 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNOkotDMvktb"
      },
      "source": [
        "#Bad Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x02iw-TRuI7r",
        "outputId": "60d98024-2f94-41da-ab83-c3c8d35853cf"
      },
      "source": [
        "from keras import callbacks\n",
        "\n",
        "junk = np.random.random((10000, 1))\n",
        "model2C = models.Sequential()\n",
        "model2C.add(layers.Dense(4096*4, activation='relu', input_shape=(2,)))\n",
        "model2C.add(layers.Dense(1, activation='linear'))\n",
        "model2C.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "callbacks = [callbacks.EarlyStopping(patience=6), callbacks.ReduceLROnPlateau()]\n",
        "model2C.fit(train, junk, epochs=100, batch_size=512, validation_split=0.3, callbacks=callbacks)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.1394 - val_loss: 0.1172 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 1s 66ms/step - loss: 0.0966 - val_loss: 0.0913 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0866 - val_loss: 0.0867 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0845 - val_loss: 0.0864 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0841 - val_loss: 0.0862 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0840 - val_loss: 0.0865 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0845 - val_loss: 0.0862 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0841 - val_loss: 0.0864 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0842 - val_loss: 0.0861 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.0841 - val_loss: 0.0861 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0840 - val_loss: 0.0866 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0841 - val_loss: 0.0861 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0841 - val_loss: 0.0860 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.0840 - val_loss: 0.0861 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0842 - val_loss: 0.0864 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0842 - val_loss: 0.0875 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0845 - val_loss: 0.0860 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.0845 - val_loss: 0.0868 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.0843 - val_loss: 0.0865 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0842 - val_loss: 0.0860 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0840 - val_loss: 0.0863 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.0842 - val_loss: 0.0861 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.0839 - val_loss: 0.0860 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe44542aad0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfYVfwJiy51-",
        "outputId": "f4e127cb-b1d8-410b-e973-19ecbd795714"
      },
      "source": [
        "test_results_2C = model2C.predict(test)\n",
        "test,test_results_2C"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.52025425],\n",
              "        [0.5201312 ],\n",
              "        [0.5166615 ],\n",
              "        [0.51767635],\n",
              "        [0.5211427 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKQ4EaRt6uF_"
      },
      "source": [
        "#Save and Load Models\n",
        "model2A.save('savedModel')\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqma1sj37IX6"
      },
      "source": [
        "from tensorflow import keras\n",
        "model3 = keras.models.load_model('savedModel')\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRhKO2ND7bEd",
        "outputId": "cd2ee250-d327-4f9c-944c-adc94141a8bc"
      },
      "source": [
        "test_result3 = model3.predict(test)\n",
        "test,test_result3"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe44758d710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.2, 0.5], [0.3, 0.6], [0.4, 0.7], [0.5, 0.8], [0.6, 0.9]],\n",
              " array([[0.09987218],\n",
              "        [0.17976484],\n",
              "        [0.27954772],\n",
              "        [0.39958486],\n",
              "        [0.5393298 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Last Tested\n",
        "!date"
      ],
      "metadata": {
        "id": "IW5dfJuT0CF1",
        "outputId": "15262703-0e43-43a9-d3ac-8e051420ff60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 28 09:38:45 UTC 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5rXqlSSQs8"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAdRK93QcEIh"
      },
      "source": [
        "![CC-BY-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png) The contents of this website are released under creative commons "
      ]
    }
  ]
}